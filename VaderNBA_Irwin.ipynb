{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting NBA Games using Twitter Sentiment Analysis\n",
    "\n",
    "### COSC76 - Data Mining & Knowledge Discovery\n",
    "\n",
    "## Nicholas Irwin\n",
    "\n",
    "\n",
    "### Libraries Used:\n",
    "\n",
    "- Pandas\n",
    "- Numpy\n",
    "- snscrape\n",
    "- Tweepy\n",
    "- Requests\n",
    "- NLTK\n",
    "- sklearn\n",
    "- Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snscrape in /opt/anaconda3/lib/python3.8/site-packages (0.3.4)\n",
      "Requirement already satisfied: requests[socks] in /opt/anaconda3/lib/python3.8/site-packages (from snscrape) (2.24.0)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.8/site-packages (from snscrape) (4.6.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.8/site-packages (from snscrape) (4.9.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (2020.6.20)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->snscrape) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_command(num_tweets,start_date,end_date,query,filename):\n",
    "\n",
    "    command=\"snscrape --max-results \"+num_tweets+\" --since \"+start_date+\" twitter-search \"+'\"'+query+\" until:\"+end_date+'\" > '+filename\n",
    "    return command\n",
    "\n",
    "# command=create_command('50','2018-10-17','2018-10-18','Lakers lang:en','lakers-18-19-game1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key='I9MAEamzxtjPUYlvp9FTTFlAE'\n",
    "consumer_secret= 'TzbxXtXMfOz0QzaaVz53nny2vmJmfZ6Im36KiHav1uYG2JUgwM'\n",
    "access_token= '1349400132912099329-nfVXMlB3FSs24z3m3V7LyPUpx0MyzS' \n",
    "access_token_secret= 'zfc3Vv2WHo3RQMrkar6rFuuzkIXCGqyDXxCLb9c22HQhc'\n",
    "\n",
    "auth=tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "api=tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos Sentiment</th>\n",
       "      <th>Neg Sentiment</th>\n",
       "      <th>Neu Sentiment</th>\n",
       "      <th>Compound Sentiment</th>\n",
       "      <th>Category</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pos Sentiment Neg Sentiment Neu Sentiment Compound Sentiment Category  \\\n",
       "0           NaN           NaN           NaN                NaN        W   \n",
       "1           NaN           NaN           NaN                NaN        W   \n",
       "2           NaN           NaN           NaN                NaN        W   \n",
       "3           NaN           NaN           NaN                NaN        W   \n",
       "4           NaN           NaN           NaN                NaN        L   \n",
       "\n",
       "   Result  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def create_team_df(url):\n",
    "    html=requests.get(url)\n",
    "    page_content=html.content\n",
    "    table=pd.read_html(page_content)\n",
    "    results=table[0]\n",
    "    results_list=results[2]\n",
    "    results_list_cleaned=list(results_list[1:])\n",
    "    list2=[]\n",
    "    for result in results_list_cleaned:\n",
    "        list2.append(result[:1])\n",
    "    \n",
    "    list3=list2[:41]\n",
    "    \n",
    "    num_games=list(range(41))\n",
    "    team_df=pd.DataFrame(index=num_games, columns=['Pos Sentiment','Neg Sentiment','Neu Sentiment','Compound Sentiment','Category'])\n",
    "    team_df['Category']=list3\n",
    "    team_df['Result']=[1 if o=='W' else 0 for o in team_df['Category']]\n",
    "    \n",
    "    return team_df\n",
    "\n",
    "\n",
    "pistons_url=\"https://www.espn.in/nba/team/schedule/_/name/Det/season/2019/seasontype/2\"\n",
    "pistons_df=create_team_df(pistons_url)\n",
    "\n",
    "lakers_url=\"https://www.espn.com/nba/team/schedule/_/name/lal/season/2019\"\n",
    "lakers_df=create_team_df(lakers_url)\n",
    "\n",
    "pistons_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excluding the second of back-to-back games--NOT -- would mess up inputting of W/L from html\n",
    "lakers_dates=[('2018-10-17','2018-10-18'),('2018-10-19','2018-10-20'),('2018-10-21','2018-10-22'),\n",
    "              ('2018-10-23','2018-10-24'),('2018-10-24','2018-10-25'),('2018-10-26','2018-10-27'),\n",
    "              ('2018-10-28','2018-10-29'),('2018-10-30','2018-10-31'),('2018-11-02','2018-11-03'),\n",
    "              ('2018-11-03','2018-11-04'),('2018-11-06','2018-11-07'),('2018-11-09','2018-11-10'),\n",
    "              ('2018-11-10','2018-11-11'),('2018-11-13','2018-11-14'),('2018-11-16','2018-11-17'),\n",
    "              ('2018-11-17','2018-11-18'),('2018-11-20','2018-11-21'),('2018-11-22','2018-11-23'),\n",
    "              ('2018-11-24','2018-11-25'),('2018-11-26','2018-11-27'),('2018-11-28','2018-11-29'),\n",
    "              ('2018-11-29','2018-11-30'),('2018-12-01','2018-12-02'),('2018-12-04','2018-12-05'),\n",
    "              ('2018-12-06','2018-12-07'),('2018-12-07','2018-12-08'),('2018-12-09','2018-12-10'),\n",
    "              ('2018-12-12','2018-12-13'),('2018-12-14','2018-12-15'),('2018-12-15','2018-12-16'),\n",
    "              ('2018-12-17','2018-12-18'),('2018-12-20','2018-12-21'),('2018-12-22','2018-12-23'),\n",
    "              ('2018-12-24','2018-12-25'),('2018-12-26','2018-12-27'),('2018-12-27','2018-12-28'),\n",
    "              ('2018-12-29','2018-12-30'),('2019-01-01','2019-01-02'),('2019-01-03','2019-01-04'),\n",
    "              ('2019-01-05','2019-01-06'),('2019-01-06','2019-01-07')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pistons_dates=[('2018-10-16','2018-10-17'),('2018-10-19','2018-10-20'),('2018-10-22','2018-10-23'),\n",
    "               ('2018-10-24','2018-10-25'),('2018-10-26','2018-10-27'),('2018-10-29','2018-10-30'),\n",
    "               ('2018-10-30','2018-10-31'),('2018-11-02','2018-11-03'),('2018-11-04','2018-11-05'),\n",
    "               ('2018-11-06','2018-11-07'),('2018-11-08','2018-11-09'),('2018-11-10','2018-11-11'),\n",
    "               ('2018-11-13','2018-11-14'),('2018-11-18','2018-11-19'),('2018-11-20','2018-11-21'),\n",
    "               ('2018-11-22','2018-11-23'),('2018-11-24','2018-11-25'),('2018-11-26','2018-11-27'),\n",
    "               ('2018-11-29','2018-11-30'),('2018-11-30','2018-12-01'),('2018-12-02','2018-12-03'),\n",
    "               ('2018-12-04','2018-12-05'),('2018-12-06','2018-12-07'),('2018-12-08','2018-12-09'),\n",
    "               ('2018-12-09','2018-12-10'),('2018-12-11','2018-12-12'),('2018-12-14','2018-12-15'),\n",
    "               ('2018-12-16','2018-12-17'),('2018-12-18','2018-12-19'),('2018-12-20','2018-12-21'),\n",
    "               ('2018-12-22','2018-12-23'),('2018-12-25','2018-12-26'),('2018-12-27','2018-12-28'),\n",
    "               ('2018-12-29','2018-12-30'),('2018-12-31','2019-01-01'),('2019-01-01','2019-01-02'),\n",
    "               ('2019-01-04','2019-01-05'),('2019-01-06','2019-01-07'),('2019-01-08','2019-01-09'),\n",
    "               ('2019-01-09','2019-01-10'),('2019-01-11','2019-01-12')]\n",
    "\n",
    "games_list=list(range(1,42))\n",
    "\n",
    "def create_tweet_files(search_n_str,team_dates,team_name):\n",
    "    team_start_list=(date[0] for date in team_dates)\n",
    "    team_end_list=(date[1] for date in team_dates)\n",
    "    \n",
    "    for start, end, game in zip(team_start_list,team_end_list,games_list):\n",
    "        command=create_command(search_n_str,start,end,team_name+' lang:en',team_name+'-18-19-game'+str(game)+'.txt')\n",
    "        os.system(command)\n",
    "\n",
    "create_tweet_files('50',pistons_dates,\"Pistons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tweet_files('50',lakers_dates,\"Lakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I FOUND THE OS.LISTDIR AND OS.PATH.JOIN FUNCTIONALITIES ON STACK EXCHANGE\n",
    "#I WAS GOING TO MAKE A LIST OF THE FILENAMES BUT I KNEW THERE HAD TO BE A WAY TO LOOP THRU FILES IN A DIRECTORY\n",
    "\n",
    "# for each txt file(each game), make list of tweet ids by reading and parsing txt file\n",
    "lakers_lol_tweet_ids=[]\n",
    "\n",
    "for filename in os.listdir('./lakers_games_tweets'):\n",
    "    tweet_ids=[]\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join('./lakers_games_tweets', filename)) as fin:\n",
    "            lines=fin.readlines()\n",
    "            for line in lines:\n",
    "                line=line.replace('\\n','')\n",
    "                line=line.split('/')\n",
    "                tweet_id=line[-1]\n",
    "                tweet_ids.append(tweet_id)\n",
    "        lakers_lol_tweet_ids.append(tweet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pistons_lol_tweet_ids=[]\n",
    "\n",
    "for filename in os.listdir('./pistons_games_tweets'):\n",
    "    \n",
    "    tweet_ids=[]\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(os.path.join('./pistons_games_tweets', filename)) as fin:\n",
    "            lines=fin.readlines()\n",
    "            for line in lines:\n",
    "                line=line.replace('\\n','')\n",
    "                line=line.split('/')\n",
    "                tweet_id=line[-1]\n",
    "                tweet_ids.append(tweet_id)\n",
    "        pistons_lol_tweet_ids.append(tweet_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1074091709091450881', '1074091687880749056', '1074091677550288896', '1074091624022638592', '1074091469517012992', '1074091464781643781', '1074091444699316224', '1074091384913580032', '1074091347252981761', '1074091298703826945', '1074091286163013634', '1074091257771610112', '1074091221633634306', '1074091217087053825', '1074091146094116864', '1074091140113096704', '1074091060001992706', '1074091052510953473', '1074091010366599168', '1074090995791396864', '1074090958889848832', '1074090933287817217', '1074090919069212673', '1074090908180725760', '1074090762722205696', '1074090736348487686', '1074090730866511874', '1074090680698454017', '1074090679876444160', '1074090665200500736', '1074090599236685824', '1074090540445126657', '1074090529615462405', '1074090484170141696', '1074090438640979968', '1074090436229296130', '1074090388921683968', '1074090322882424832', '1074090318608388096', '1074090285934829568', '1074090261892874240', '1074090220059009024', '1074090185044971523', '1074090136533721088', '1074090099791552513', '1074090069068275712', '1074090030413570050', '1074089983839854593', '1074089958154096642', '1074089922854825987']\n"
     ]
    }
   ],
   "source": [
    "print(lakers_lol_tweet_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-536aee2d2e9b>:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_df['Pos Sentiment'][i]=statistics.mean(pos_list)\n",
      "<ipython-input-12-536aee2d2e9b>:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_df['Neg Sentiment'][i]=statistics.mean(neg_list)\n",
      "<ipython-input-12-536aee2d2e9b>:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_df['Neu Sentiment'][i]=statistics.mean(neu_list)\n",
      "<ipython-input-12-536aee2d2e9b>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_df['Compound Sentiment'][i]=statistics.mean(compound_list)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos Sentiment</th>\n",
       "      <th>Neg Sentiment</th>\n",
       "      <th>Neu Sentiment</th>\n",
       "      <th>Compound Sentiment</th>\n",
       "      <th>Category</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.0578462</td>\n",
       "      <td>0.85974</td>\n",
       "      <td>0.214869</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174212</td>\n",
       "      <td>0.0919655</td>\n",
       "      <td>0.828224</td>\n",
       "      <td>0.168839</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130567</td>\n",
       "      <td>0.0905714</td>\n",
       "      <td>0.868327</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.177344</td>\n",
       "      <td>0.0848077</td>\n",
       "      <td>0.835833</td>\n",
       "      <td>0.241876</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148667</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>0.847898</td>\n",
       "      <td>0.139578</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pos Sentiment Neg Sentiment Neu Sentiment Compound Sentiment Category  \\\n",
       "0        0.1574     0.0578462       0.85974           0.214869        L   \n",
       "1      0.174212     0.0919655      0.828224           0.168839        L   \n",
       "2      0.130567     0.0905714      0.868327             0.1334        L   \n",
       "3      0.177344     0.0848077      0.835833           0.241876        W   \n",
       "4      0.148667      0.103172      0.847898           0.139578        W   \n",
       "\n",
       "   Result  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer=SentimentIntensityAnalyzer()\n",
    "\n",
    "def fill_team_df(lol_tweet_ids,team_df):\n",
    "    \n",
    "    for tweet_ids in lol_tweet_ids:\n",
    "        i=lol_tweet_ids.index(tweet_ids)\n",
    "        # make empty list of tweet compound sentiments\n",
    "        pos_list=[]\n",
    "        neg_list=[]\n",
    "        neu_list=[]\n",
    "        compound_list=[]\n",
    "        \n",
    "        if len(tweet_ids)>0:\n",
    "            tweet_statuses=api.statuses_lookup(tweet_ids)\n",
    "\n",
    "            for tweet in tweet_statuses:\n",
    "\n",
    "                tweet=tweet._json\n",
    "\n",
    "                pos_list.append(analyzer.polarity_scores(tweet['text'])['pos'])\n",
    "                neg_list.append(analyzer.polarity_scores(tweet['text'])['neg'])\n",
    "                neu_list.append(analyzer.polarity_scores(tweet['text'])['neu'])\n",
    "                compound_list.append(analyzer.polarity_scores(tweet['text'])['compound'])\n",
    "\n",
    "            for (x,y) in zip(pos_list,neg_list):\n",
    "                if x==0:\n",
    "                    pos_list.remove(x)\n",
    "                if y==0:\n",
    "                    neg_list.remove(y)\n",
    "            \n",
    "            for (w,z) in zip(neu_list,compound_list):\n",
    "                if w==0:\n",
    "                    neu_list.remove(w)\n",
    "                if z==0:\n",
    "                    compound_list.remove(z)\n",
    "\n",
    "            team_df['Pos Sentiment'][i]=statistics.mean(pos_list)\n",
    "            team_df['Neg Sentiment'][i]=statistics.mean(neg_list)\n",
    "            team_df['Neu Sentiment'][i]=statistics.mean(neu_list)\n",
    "            team_df['Compound Sentiment'][i]=statistics.mean(compound_list)\n",
    "        \n",
    "\n",
    "    return team_df\n",
    "        \n",
    "lakers_df2=fill_team_df(lakers_lol_tweet_ids,lakers_df)\n",
    "lakers_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-536aee2d2e9b>:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_df['Pos Sentiment'][i]=statistics.mean(pos_list)\n",
      "<ipython-input-12-536aee2d2e9b>:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_df['Neg Sentiment'][i]=statistics.mean(neg_list)\n",
      "<ipython-input-12-536aee2d2e9b>:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_df['Neu Sentiment'][i]=statistics.mean(neu_list)\n",
      "<ipython-input-12-536aee2d2e9b>:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  team_df['Compound Sentiment'][i]=statistics.mean(compound_list)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos Sentiment</th>\n",
       "      <th>Neg Sentiment</th>\n",
       "      <th>Neu Sentiment</th>\n",
       "      <th>Compound Sentiment</th>\n",
       "      <th>Category</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.199656</td>\n",
       "      <td>0.0797143</td>\n",
       "      <td>0.816553</td>\n",
       "      <td>0.205835</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0619655</td>\n",
       "      <td>0.883735</td>\n",
       "      <td>0.141265</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104417</td>\n",
       "      <td>0.0668214</td>\n",
       "      <td>0.88742</td>\n",
       "      <td>0.149149</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.126484</td>\n",
       "      <td>0.0698462</td>\n",
       "      <td>0.880521</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130259</td>\n",
       "      <td>0.0783103</td>\n",
       "      <td>0.879417</td>\n",
       "      <td>0.0932258</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.137121</td>\n",
       "      <td>0.0577692</td>\n",
       "      <td>0.87942</td>\n",
       "      <td>0.19095</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.123687</td>\n",
       "      <td>0.050963</td>\n",
       "      <td>0.89334</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.102933</td>\n",
       "      <td>0.0738621</td>\n",
       "      <td>0.893245</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.138031</td>\n",
       "      <td>0.0962333</td>\n",
       "      <td>0.847854</td>\n",
       "      <td>0.0884829</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.155538</td>\n",
       "      <td>0.07468</td>\n",
       "      <td>0.838102</td>\n",
       "      <td>0.25565</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Pos Sentiment Neg Sentiment Neu Sentiment Compound Sentiment Category  \\\n",
       "0      0.199656     0.0797143      0.816553           0.205835        W   \n",
       "1          0.13     0.0619655      0.883735           0.141265        W   \n",
       "2      0.104417     0.0668214       0.88742           0.149149        W   \n",
       "3      0.126484     0.0698462      0.880521             0.1178        W   \n",
       "4      0.130259     0.0783103      0.879417          0.0932258        L   \n",
       "5      0.137121     0.0577692       0.87942            0.19095        L   \n",
       "6      0.123687      0.050963       0.89334             0.1594        L   \n",
       "7      0.102933     0.0738621      0.893245             0.0738        L   \n",
       "8      0.138031     0.0962333      0.847854          0.0884829        L   \n",
       "9      0.155538       0.07468      0.838102            0.25565        W   \n",
       "\n",
       "   Result  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pistons_df2=fill_team_df(pistons_lol_tweet_ids,pistons_df)\n",
    "pistons_df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pos Sentiment</th>\n",
       "      <th>Neg Sentiment</th>\n",
       "      <th>Neu Sentiment</th>\n",
       "      <th>Compound Sentiment</th>\n",
       "      <th>Category</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.0578462</td>\n",
       "      <td>0.85974</td>\n",
       "      <td>0.214869</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174212</td>\n",
       "      <td>0.0919655</td>\n",
       "      <td>0.828224</td>\n",
       "      <td>0.168839</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130567</td>\n",
       "      <td>0.0905714</td>\n",
       "      <td>0.868327</td>\n",
       "      <td>0.1334</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.177344</td>\n",
       "      <td>0.0848077</td>\n",
       "      <td>0.835833</td>\n",
       "      <td>0.241876</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148667</td>\n",
       "      <td>0.103172</td>\n",
       "      <td>0.847898</td>\n",
       "      <td>0.139578</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.148088</td>\n",
       "      <td>0.0741</td>\n",
       "      <td>0.85482</td>\n",
       "      <td>0.174618</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0641111</td>\n",
       "      <td>0.110154</td>\n",
       "      <td>0.904333</td>\n",
       "      <td>-0.1245</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.186083</td>\n",
       "      <td>0.05925</td>\n",
       "      <td>0.83286</td>\n",
       "      <td>0.32333</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.155581</td>\n",
       "      <td>0.107517</td>\n",
       "      <td>0.827348</td>\n",
       "      <td>0.0837914</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0483043</td>\n",
       "      <td>0.0809231</td>\n",
       "      <td>0.928556</td>\n",
       "      <td>-0.0369654</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pos Sentiment Neg Sentiment Neu Sentiment Compound Sentiment Category  \\\n",
       "0         0.1574     0.0578462       0.85974           0.214869        L   \n",
       "1       0.174212     0.0919655      0.828224           0.168839        L   \n",
       "2       0.130567     0.0905714      0.868327             0.1334        L   \n",
       "3       0.177344     0.0848077      0.835833           0.241876        W   \n",
       "4       0.148667      0.103172      0.847898           0.139578        W   \n",
       "..           ...           ...           ...                ...      ...   \n",
       "77      0.148088        0.0741       0.85482           0.174618        L   \n",
       "78     0.0641111      0.110154      0.904333            -0.1245        L   \n",
       "79      0.186083       0.05925       0.83286            0.32333        L   \n",
       "80      0.155581      0.107517      0.827348          0.0837914        L   \n",
       "81     0.0483043     0.0809231      0.928556         -0.0369654        W   \n",
       "\n",
       "    Result  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        1  \n",
       "..     ...  \n",
       "77       0  \n",
       "78       0  \n",
       "79       0  \n",
       "80       0  \n",
       "81       1  \n",
       "\n",
       "[82 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine dataframes from both teams, get rid of NaNs\n",
    "team_frames=[lakers_df2,pistons_df2]\n",
    "final_df=pd.concat(team_frames,ignore_index=True)\n",
    "\n",
    "final_df=final_df.dropna()\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_four=final_df[['Pos Sentiment','Neg Sentiment','Neu Sentiment','Compound Sentiment']]\n",
    "x_array_four=x_df_four.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_compound=final_df[['Compound Sentiment']]\n",
    "x_array_compound=x_df_compound.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_pos=final_df[['Pos Sentiment']]\n",
    "x_array_pos=x_df_pos.to_numpy()\n",
    "# x_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_neg=final_df[['Neg Sentiment']]\n",
    "x_array_neg=x_df_neg.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df_neu=final_df[['Neu Sentiment']]\n",
    "x_array_neu=x_df_neu.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now build and test as many models as possible on this dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "models_features_list=[\"Logistic Regression Four\",\"Random Forest Four\",\"K Nearest Neighbours(3) Four\",\"K Nearest Neighbours (5) Four\",\n",
    "                      \"Logistic Regression Pos\",\"Random Forest Pos\",\"K Nearest Neighbours(3) Pos\",\"K Nearest Neighbours (5) Pos\",\n",
    "                      \"Logistic Regression Neg\",\"Random Forest Neg\",\"K Nearest Neighbours(3) Neg\",\"K Nearest Neighbours (5) Neg\",\n",
    "                      \"Logistic Regression Neu\",\"Random Forest Neu\",\"K Nearest Neighbours(3) Neu\",\"K Nearest Neighbours (5) Neu\",\n",
    "                      \"Logistic Regression Compound\",\"Random Forest Compound\",\"K Nearest Neighbours(3) Compound\",\"K Nearest Neighbours (5) Compound\",\n",
    "            \n",
    "                     ]\n",
    "\n",
    "models_df=pd.DataFrame(index=models_features_list,columns=['F1 Default List','F1 Weighted List','Model Accuracy'])\n",
    "\n",
    "# Train and evaluate (using 5-fold cross validation) the following models\n",
    "f1_default_list=[]\n",
    "f1_weighted_list=[]\n",
    "model_accuracy_list=[]\n",
    "\n",
    "def model_selector(model):\n",
    "    if model=='LR':\n",
    "        return LogisticRegression()\n",
    "    elif model=='RF':\n",
    "        return RandomForestClassifier(n_estimators=10)\n",
    "    elif model=='KN3':\n",
    "        return KNeighborsClassifier(n_neighbors=3)\n",
    "    elif model=='KN5':\n",
    "        return KNeighborsClassifier(n_neighbors=5)\n",
    "    return LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0]\n",
      "[0.0, 0.403059163059163]\n",
      "[0.0, 0.403059163059163, 0.493968253968254]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111]\n"
     ]
    }
   ],
   "source": [
    "# FOUR\n",
    "\n",
    "X_train_four, X_test_four, y_train_four, y_test_four = train_test_split(x_array_four,final_df['Result'],test_size=0.20,random_state=42)\n",
    "\n",
    "\n",
    "LR_four=model_selector('LR').fit(X_train_four,y_train_four)\n",
    "RF_four=model_selector('RF').fit(X_train_four,y_train_four)\n",
    "KN3_four=model_selector('KN3').fit(X_train_four,y_train_four)\n",
    "KN5_four=model_selector('KN5').fit(X_train_four,y_train_four)\n",
    "\n",
    "\n",
    "# ALL FOUR SENTIMENT FEATURES\n",
    "f1_default_list.append(cross_val_score(LR_four,X_train_four,y_train_four,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "f1_default_list.append(cross_val_score(RF_four,X_train_four,y_train_four,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(KN3_four,X_train_four,y_train_four,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(KN5_four,X_train_four,y_train_four,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "# ALL FOUR SENTIMENT FEATURES\n",
    "f1_weighted_list.append(cross_val_score(LR_four,X_train_four,y_train_four,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(RF_four,X_train_four,y_train_four,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN3_four,X_train_four,y_train_four,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN5_four,X_train_four,y_train_four,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "\n",
    "# ALL FOUR SENTIMENT FEATURES\n",
    "model_accuracy_list.append(cross_val_score(LR_four,X_train_four,y_train_four,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(RF_four,X_train_four,y_train_four,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN3_four,X_train_four,y_train_four,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN5_four,X_train_four,y_train_four,scoring=make_scorer(f1_score)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# POS\n",
    "\n",
    "X_train_pos, X_test_pos, y_train_pos, y_test_pos = train_test_split(x_array_pos,final_df['Result'],test_size=0.20,random_state=42)\n",
    "\n",
    "\n",
    "LR_pos=model_selector('LR').fit(X_train_pos,y_train_pos)\n",
    "RF_pos=model_selector('RF').fit(X_train_pos,y_train_pos)\n",
    "KN3_pos=model_selector('KN3').fit(X_train_pos,y_train_pos)\n",
    "KN5_pos=model_selector('KN5').fit(X_train_pos,y_train_pos)\n",
    "\n",
    "# ONLY POSITIVE SENTIMENT FEATURES\n",
    "f1_default_list.append(cross_val_score(LR_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(RF_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(KN3_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(KN5_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "print(len(f1_default_list))\n",
    "\n",
    "\n",
    "# ONLY POSITIVE SENTIMENT FEATURES\n",
    "f1_weighted_list.append(cross_val_score(LR_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(RF_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN3_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN5_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "\n",
    "# ONLY POSITIVE SENTIMENT FEATURES\n",
    "model_accuracy_list.append(cross_val_score(LR_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(RF_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN3_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN5_pos,X_train_pos,y_train_pos,scoring=make_scorer(f1_score)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664, 0.0]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664, 0.0, 0.5341549953314659]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664, 0.0, 0.5341549953314659, 0.4171428571428571]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664, 0.0, 0.5341549953314659, 0.4171428571428571, 0.2778542510121457]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# NEG\n",
    "\n",
    "X_train_neg, X_test_neg, y_train_neg, y_test_neg = train_test_split(x_array_neg,final_df['Result'],test_size=0.20,random_state=42)\n",
    "\n",
    "\n",
    "LR_neg=model_selector('LR').fit(X_train_neg,y_train_neg)\n",
    "RF_neg=model_selector('RF').fit(X_train_neg,y_train_neg)\n",
    "KN3_neg=model_selector('KN3').fit(X_train_neg,y_train_neg)\n",
    "KN5_neg=model_selector('KN5').fit(X_train_neg,y_train_neg)\n",
    "\n",
    "\n",
    "# ONLY NEGATIVE SENTIMENT FEATURES\n",
    "f1_default_list.append(cross_val_score(LR_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(RF_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(KN3_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(KN5_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "print(len(f1_default_list))\n",
    "\n",
    "\n",
    "# ONLY NEGATIVE SENTIMENT FEATURES\n",
    "f1_weighted_list.append(cross_val_score(LR_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(RF_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN3_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN5_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "\n",
    "# ONLY NEGATIVE SENTIMENT FEATURES\n",
    "model_accuracy_list.append(cross_val_score(LR_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(RF_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN3_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN5_neg,X_train_neg,y_train_neg,scoring=make_scorer(f1_score)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664, 0.0, 0.5341549953314659, 0.4171428571428571, 0.2778542510121457, 0.0]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664, 0.0, 0.5341549953314659, 0.4171428571428571, 0.2778542510121457, 0.0, 0.47857142857142865]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664, 0.0, 0.5341549953314659, 0.4171428571428571, 0.2778542510121457, 0.0, 0.47857142857142865, 0.47836829836829836]\n",
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664, 0.0, 0.5341549953314659, 0.4171428571428571, 0.2778542510121457, 0.0, 0.47857142857142865, 0.47836829836829836, 0.38464646464646457]\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# NEUTRAL\n",
    "\n",
    "X_train_neu, X_test_neu, y_train_neu, y_test_neu = train_test_split(x_array_neu,final_df['Result'],test_size=0.20,random_state=42)\n",
    "\n",
    "\n",
    "LR_neu=model_selector('LR').fit(X_train_neu,y_train_neu)\n",
    "RF_neu=model_selector('RF').fit(X_train_neu,y_train_neu)\n",
    "KN3_neu=model_selector('KN3').fit(X_train_neu,y_train_neu)\n",
    "KN5_neu=model_selector('KN5').fit(X_train_neu,y_train_neu)\n",
    "\n",
    "\n",
    "# ONLY NEUTRAL SENTIMENT FEATURES\n",
    "f1_default_list.append(cross_val_score(LR_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(RF_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(KN3_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "\n",
    "f1_default_list.append(cross_val_score(KN5_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score)).mean())\n",
    "print(f1_default_list)\n",
    "print(len(f1_default_list))\n",
    "\n",
    "# ONLY NEUTRAL SENTIMENT FEATURES\n",
    "f1_weighted_list.append(cross_val_score(LR_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(RF_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN3_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN5_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "\n",
    "# ONLY NEUTRAL SENTIMENT FEATURES\n",
    "model_accuracy_list.append(cross_val_score(LR_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(RF_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN3_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN5_neu,X_train_neu,y_train_neu,scoring=make_scorer(f1_score)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# COMPOUND\n",
    "\n",
    "X_train_compound, X_test_compound, y_train_compound, y_test_compound = train_test_split(x_array_compound,final_df['Result'],test_size=0.20,random_state=42)\n",
    "\n",
    "\n",
    "LR_compound=model_selector('LR').fit(X_train_compound,y_train_compound)\n",
    "RF_compound=model_selector('RF').fit(X_train_compound,y_train_compound)\n",
    "KN3_compound=model_selector('KN3').fit(X_train_compound,y_train_compound)\n",
    "KN5_compound=model_selector('KN5').fit(X_train_compound,y_train_compound)\n",
    "\n",
    "\n",
    "# ONLY COMPOUND SENTIMENT FEATURES\n",
    "f1_default_list.append(cross_val_score(LR_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score)).mean())\n",
    "f1_default_list.append(cross_val_score(RF_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score)).mean())\n",
    "f1_default_list.append(cross_val_score(KN3_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score)).mean())\n",
    "f1_default_list.append(cross_val_score(KN5_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score)).mean())\n",
    "print(len(f1_default_list))\n",
    "\n",
    "\n",
    "# ONLY COMPOUND SENTIMENT FEATURES\n",
    "f1_weighted_list.append(cross_val_score(LR_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(RF_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN3_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "f1_weighted_list.append(cross_val_score(KN5_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score,average='weighted')).mean())\n",
    "\n",
    "# ONLY COMPOUND SENTIMENT FEATURES\n",
    "model_accuracy_list.append(cross_val_score(LR_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(RF_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN3_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score)).mean())\n",
    "model_accuracy_list.append(cross_val_score(KN5_compound,X_train_compound,y_train_compound,scoring=make_scorer(f1_score)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.403059163059163, 0.493968253968254, 0.5511111111111111, 0.0, 0.32, 0.3776334776334776, 0.4664335664335664, 0.0, 0.5341549953314659, 0.4171428571428571, 0.2778542510121457, 0.0, 0.47857142857142865, 0.47836829836829836, 0.38464646464646457, 0.0, 0.4556410256410256, 0.3429470529470529, 0.3713308913308913]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Default List</th>\n",
       "      <th>F1 Weighted List</th>\n",
       "      <th>Model Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression Four</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352470</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Four</th>\n",
       "      <td>0.403059</td>\n",
       "      <td>0.499996</td>\n",
       "      <td>0.513607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours(3) Four</th>\n",
       "      <td>0.493968</td>\n",
       "      <td>0.546905</td>\n",
       "      <td>0.493968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours (5) Four</th>\n",
       "      <td>0.551111</td>\n",
       "      <td>0.625486</td>\n",
       "      <td>0.551111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression Pos</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359838</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Pos</th>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.446169</td>\n",
       "      <td>0.425641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours(3) Pos</th>\n",
       "      <td>0.377633</td>\n",
       "      <td>0.435512</td>\n",
       "      <td>0.377633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours (5) Pos</th>\n",
       "      <td>0.466434</td>\n",
       "      <td>0.527677</td>\n",
       "      <td>0.466434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression Neg</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359838</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Neg</th>\n",
       "      <td>0.534155</td>\n",
       "      <td>0.599240</td>\n",
       "      <td>0.585803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours(3) Neg</th>\n",
       "      <td>0.417143</td>\n",
       "      <td>0.485982</td>\n",
       "      <td>0.417143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours (5) Neg</th>\n",
       "      <td>0.277854</td>\n",
       "      <td>0.347413</td>\n",
       "      <td>0.277854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression Neu</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359838</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Neu</th>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.509779</td>\n",
       "      <td>0.486869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours(3) Neu</th>\n",
       "      <td>0.478368</td>\n",
       "      <td>0.515513</td>\n",
       "      <td>0.478368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours (5) Neu</th>\n",
       "      <td>0.384646</td>\n",
       "      <td>0.479518</td>\n",
       "      <td>0.384646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression Compound</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.359838</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Compound</th>\n",
       "      <td>0.455641</td>\n",
       "      <td>0.541838</td>\n",
       "      <td>0.469451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours(3) Compound</th>\n",
       "      <td>0.342947</td>\n",
       "      <td>0.427413</td>\n",
       "      <td>0.342947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours (5) Compound</th>\n",
       "      <td>0.371331</td>\n",
       "      <td>0.492353</td>\n",
       "      <td>0.371331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   F1 Default List  F1 Weighted List  \\\n",
       "Logistic Regression Four                  0.000000          0.352470   \n",
       "Random Forest Four                        0.403059          0.499996   \n",
       "K Nearest Neighbours(3) Four              0.493968          0.546905   \n",
       "K Nearest Neighbours (5) Four             0.551111          0.625486   \n",
       "Logistic Regression Pos                   0.000000          0.359838   \n",
       "Random Forest Pos                         0.320000          0.446169   \n",
       "K Nearest Neighbours(3) Pos               0.377633          0.435512   \n",
       "K Nearest Neighbours (5) Pos              0.466434          0.527677   \n",
       "Logistic Regression Neg                   0.000000          0.359838   \n",
       "Random Forest Neg                         0.534155          0.599240   \n",
       "K Nearest Neighbours(3) Neg               0.417143          0.485982   \n",
       "K Nearest Neighbours (5) Neg              0.277854          0.347413   \n",
       "Logistic Regression Neu                   0.000000          0.359838   \n",
       "Random Forest Neu                         0.478571          0.509779   \n",
       "K Nearest Neighbours(3) Neu               0.478368          0.515513   \n",
       "K Nearest Neighbours (5) Neu              0.384646          0.479518   \n",
       "Logistic Regression Compound              0.000000          0.359838   \n",
       "Random Forest Compound                    0.455641          0.541838   \n",
       "K Nearest Neighbours(3) Compound          0.342947          0.427413   \n",
       "K Nearest Neighbours (5) Compound         0.371331          0.492353   \n",
       "\n",
       "                                   Model Accuracy  \n",
       "Logistic Regression Four                 0.000000  \n",
       "Random Forest Four                       0.513607  \n",
       "K Nearest Neighbours(3) Four             0.493968  \n",
       "K Nearest Neighbours (5) Four            0.551111  \n",
       "Logistic Regression Pos                  0.000000  \n",
       "Random Forest Pos                        0.425641  \n",
       "K Nearest Neighbours(3) Pos              0.377633  \n",
       "K Nearest Neighbours (5) Pos             0.466434  \n",
       "Logistic Regression Neg                  0.000000  \n",
       "Random Forest Neg                        0.585803  \n",
       "K Nearest Neighbours(3) Neg              0.417143  \n",
       "K Nearest Neighbours (5) Neg             0.277854  \n",
       "Logistic Regression Neu                  0.000000  \n",
       "Random Forest Neu                        0.486869  \n",
       "K Nearest Neighbours(3) Neu              0.478368  \n",
       "K Nearest Neighbours (5) Neu             0.384646  \n",
       "Logistic Regression Compound             0.000000  \n",
       "Random Forest Compound                   0.469451  \n",
       "K Nearest Neighbours(3) Compound         0.342947  \n",
       "K Nearest Neighbours (5) Compound        0.371331  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f1_default_list)\n",
    "# print\n",
    "models_df['F1 Default List']=f1_default_list\n",
    "models_df['F1 Weighted List']=f1_weighted_list\n",
    "models_df['Model Accuracy']=model_accuracy_list\n",
    "\n",
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbours (5) Four\n"
     ]
    }
   ],
   "source": [
    "print(models_df[['F1 Weighted List']].idxmax()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5701357466063348\n"
     ]
    }
   ],
   "source": [
    "#Already fitted to X_train, and y_train\n",
    "best_model=RF_neg\n",
    "\n",
    "best_predictions=best_model.predict(X_test_compound)\n",
    "prediction_probs=best_model.predict_proba(X_test_compound)\n",
    "\n",
    "print(f1_score(y_test_compound,best_predictions,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_compound,[p[1] for p in prediction_probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9078574250>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(recall,precision)\n",
    "plt.scatter(recall,precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
